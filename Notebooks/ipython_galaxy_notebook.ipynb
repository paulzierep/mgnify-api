{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the interactive Galaxy IPython Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access your data via the dataset number. Using a Python kernel, you can access dataset number 42 with ``handle = open(get(42), 'r')``.\n",
    "To save data, write your data to a file, and then call ``put('filename.txt')``. The dataset will then be available in your galaxy history.\n",
    "<br>When using a non-Python kernel, ``get`` and ``put`` are available as command-line tools, which can be accessed using system calls in R, Julia, and Ruby. For example, to read dataset number 42 into R, you can write ```handle <- file(system('get -i 42', intern = TRUE))```.\n",
    "To save data in R, write the data to a file and then call ``system('put -p filename.txt')``.\n",
    "Notebooks can be saved to Galaxy by clicking the large green button at the top right of the IPython interface.<br>\n",
    "More help and informations can be found on the project [website](https://github.com/bgruening/docker-jupyter-notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting jsonapi_client\n",
      "  Downloading jsonapi_client-0.9.9-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from jsonapi_client) (2.25.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from jsonapi_client) (3.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->jsonapi_client) (20.3.0)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 62.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 98.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 96.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "\u001b[K     |████████████████████████████████| 266 kB 85.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp->jsonapi_client) (2.10)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->jsonapi_client) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from jsonschema->jsonapi_client) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->jsonapi_client) (0.17.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->jsonapi_client) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->jsonapi_client) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->jsonapi_client) (4.0.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, charset-normalizer, async-timeout, aiosignal, aiohttp, jsonapi-client\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.2.0 frozenlist-1.4.0 jsonapi-client-0.9.9 multidict-6.0.4 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonapi_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGYS00002220\n",
      "MGYS00002352\n",
      "MGYS00005656\n",
      "Could not fetch data for: MGYS00005656 using the lable: Phylum level taxonomies SSU\n",
      "MGYS00002353\n",
      "MGYS00002266\n"
     ]
    }
   ],
   "source": [
    "from jsonapi_client import Session\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "study_accessions = [\"MGYS00002220\", \"MGYS00002352\", \"MGYS00005656\", \"MGYS00002353\", \"MGYS00002266\"]\n",
    "#data_type = \"Taxonomic assignments SSU\"\n",
    "data_type = \"Phylum level taxonomies SSU\"\n",
    "\n",
    "\n",
    "data_output_folder = 'outputs/collection'\n",
    "os.makedirs(data_output_folder, exist_ok=True)\n",
    "\n",
    "for study_accession in study_accessions:\n",
    "\n",
    "    print(study_accession)\n",
    "\n",
    "    # get df of metadata and urls to data \n",
    "    with Session(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "\n",
    "        dfs = []\n",
    "        for r in mgnify.iterate(f'studies/{study_accession}/downloads'):\n",
    "            df = pd.json_normalize(r.json)\n",
    "            df['url'] = str(r.links.self)\n",
    "            dfs.append(df)\n",
    "\n",
    "    try:\n",
    "        # df of all data that can be downloaded for this study\n",
    "        main_df = pd.concat(dfs)\n",
    "\n",
    "    # get specific data table\n",
    "\n",
    "        url = main_df.loc[main_df[\"attributes.description.label\"] == data_type, \"url\"].iloc[0]\n",
    "        response = requests.get(url)\n",
    "\n",
    "        data_output_path = os.path.join(data_output_folder, f\"{study_accession}.txt\")\n",
    "        with open(data_output_path, \"w\") as f:\n",
    "            f.write(response.text)\n",
    "\n",
    "        # add to galaxy\n",
    "        put(data_output_path)\n",
    "    \n",
    "    except:\n",
    "        print(f\"Could not fetch data for: {study_accession} using the lable: {data_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
